<!DOCTYPE html>
<html>
	
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="BBSMoG: Brain-Body Synchronization for Activity- And Scene-Aware
        Human Motion Generation">
  <meta name="keywords" content="human motion generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>BBSMoG: Brain-Body Synchronization for Activity- And Scene-Aware
    Human Motion Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/cow-removebg-preview.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    body {
      margin: 0;
      padding: 0;
  }
    .video-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 16px; /* 可以根据需要调整间隔 */
        padding: 16px; /* 添加内边距以确保页面边缘对齐 */
    }

    .video-container {
        position: relative;
        overflow: hidden;
        width: 100%;
        height: 0;
        padding-bottom: 75%; /* 4:3 比例的视频容器 */
        margin-bottom: 16px;
    }

    .video {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }

    .caption {
      text-align: center;
      margin-top: 8px;
      font-size: 14px;
      color: #555;
  }
  
  .first-video-container {
    /* 例如，将第一个视频容器的左边距设置为 20px */
    margin-left: 20px;
}
</style>
</head>
<body>

    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
 
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="BBSMoG.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

     

        </div>
      </div>
    </div>

  </div>
</nav>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">BBSMoG: Brain-Body Synchronization for Activity- And Scene-Aware
            Human Motion Generation</h1>
         
            <div class="publication-links"> 
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="BBSMoG.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>  -->
              <!-- <span class="link-block">
                <a href="https://seres0.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link.
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>-->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://seres0.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div> -->
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png" width="85%" style="margin-left: auto;margin-right: auto;display: block;">
      <h2 class="subtitle has-text-centered">
        <p>&nbsp;</p>
        <span class="dnerf">BBSMoG:</span> Activity- and scene-aware human motions generated by BBSMoG. Activity instructions used for generating the sequences are
        “A person wants to try out which sofa is the most comfortable for rest” (pink), “A man on sofa wants to hide when someone knocks on the
        door” (green), and “A person wakes up due to hunger” (blue).</h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose an activity and scene-aware framework for
            diverse human motion synthesis conditioned on language
            inputs. Recent progress has shown significant improve-
            ment in generating realistic human motions in various
            controllable ways. However, these models still fall short
            of comprehending arbitrary text descriptions of desired ac-
            tivities, perceiving the environment in which human agents
            exist, and producing highly varied and natural motions that
            successfully accomplish the activities within those scenes.
            In this work, we present Brain-Body Synchronization (BB-
            SMoG in short), an adaptive motion generation framework
            that coordinates a Large Language Model (i.e., brain) and a
            Motion Diffusion Model (i.e., body) for synthesizing scene-
            and activity-aware human motion. Specifically, the key is
            to exploit the emergent capabilities in the LLM to perceive
            the surroundings and reason about essential subtasks and
            metrics involved in accomplishing the high-level (and prob-
            ably ambiguous) activity, and leverage the MDM to enable
            natural motions for performing each subtask, with an
            adaptive refinement scheme under the closed-loop guidance
            of the LLM. Our experiments demonstrate the effectiveness
            of BBSMoG to accommodate various activities and scenes
            and generate diverse and natural human motions. </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">


    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Videos of the generated motion</h2>
        <div class="subtitle has-text-centered">
          <!-- <p>&nbsp;</p> -->
          <p>We show a video of each instruction and its corresponding generated motion.
          </p>
          <!-- <img src="./static/images/figure_2_update_color.png" width="90%" style="margin-left: auto;margin-right: auto;display: block;"> -->
          <!-- <video width="640" height="360" controls>
            <source src="videos/t1.mp4" type="video/mp4">
            您的浏览器不支持 video 标签。
        </video> -->
        <div class="video-grid">
          <figure class="video-container">
            <video class="video" controls>
                <source src="videos/t4.mp4" type="video/mp4">
                您的浏览器不支持 video 标签。
            </video>
            <figcaption class="caption">视频 1 注释</figcaption>
        </figure>
      
        <figure class="video-container">
          <video class="video" controls>
              <source src="videos/t5.mp4" type="video/mp4">
              您的浏览器不支持 video 标签。
          </video>
          <figcaption class="caption">视频 2 注释</figcaption>
      </figure>
  
      <figure class="video-container">
        <video class="video" controls>
            <source src="videos/t6.mp4" type="video/mp4">
            您的浏览器不支持 video 标签。
        </video>
        <figcaption class="caption">视频 2 注释</figcaption>
    </figure>

    <figure class="video-container">
      <video class="video" controls>
          <source src="videos/t1.mp4" type="video/mp4">
          您的浏览器不支持 video 标签。
      </video>
      <figcaption class="caption">????????????????????</figcaption>
  </figure>

  <figure class="video-container">
    <video class="video" controls>
        <source src="videos/t2.mp4" type="video/mp4">
        您的浏览器不支持 video 标签。
    </video>
    <figcaption class="caption">"??????????????????"</figcaption>
</figure>

<figure class="video-container">
  <video class="video" controls>
      <source src="videos/t3.mp4" type="video/mp4">
      您的浏览器不支持 video 标签。
  </video>
  <figcaption class="caption">视频 2 注释</figcaption>
</figure>

<figure class="video-container">
  <video class="video" controls>
      <source src="videos/t10.mp4" type="video/mp4">
      您的浏览器不支持 video 标签。
  </video>
  <figcaption class="caption">视频 2 注释</figcaption>
</figure>

<figure class="video-container">
  <video class="video" controls>
      <source src="videos/t11.mp4" type="video/mp4">
      您的浏览器不支持 video 标签。
  </video>
  <figcaption class="caption">视频 2 注释</figcaption>
</figure>

<figure class="video-container">
  <video class="video" controls>
      <source src="videos/t12.mp4" type="video/mp4">
      您的浏览器不支持 video 标签。
  </video>
  <figcaption class="caption">视频 2 注释</figcaption>
</figure>

<figure class="video-container">
  <video class="video" controls>
      <source src="videos/t7.mp4" type="video/mp4">
      您的浏览器不支持 video 标签。
  </video>
  <figcaption class="caption">视频 2 注释</figcaption>
</figure>

<figure class="video-container">
  <video class="video" controls>
      <source src="videos/t8.mp4" type="video/mp4">
      您的浏览器不支持 video 标签。
  </video>
  <figcaption class="caption">视频 2 注释</figcaption>
</figure>

<figure class="video-container">
  <video class="video" controls>
      <source src="videos/t9.mp4" type="video/mp4">
      您的浏览器不支持 video 标签。
  </video>
  <figcaption class="caption">视频 2 注释</figcaption>
</figure>


          <!-- 添加更多的视频容器，以此类推 -->
      
      </div>

        </div>
        <br/>


      </div>
    </div>


  </div>
</section>




<!-- <section class="section">
  <div class="container is-max-desktop">


    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Our methods</h2>
        <div class="content has-text-justified">
          <img src="./static/images/overview.png" width="90%" style="margin-left: auto;margin-right: auto;display: block;">
          <p>&nbsp;</p>
          <p>The overall pipeline of  SERES encompasses the capability to reconstruct high-quality geometric meshes from sparse view input. We generate patches and primitives from sparse input and construct a semantic-aware neural field. The semantic matching prior for patches and the point prompt guided regularization are the fundamental components of the semantic-aware neural field. We optimize the learning of the neural field by incorporating the RGB loss obtained from volume rendering, along with the eikonal loss and the region loss obtained from point prompt-guided regularization.          </p>
        </div>
        <br/>


      </div>
    </div>


  </div>
</section> -->


<!-- <section class="section">
  <div class="container is-max-desktop">


    <div class="columns is-centered">
      <div class="column is-full-width">	
        <h2 class="title is-3">Experimental results</h2>

        <h3 class="title is-4">Three views reconstruction on the DTU benchmark</h3>
        <div class="content has-text-justified">
          <img src="./static/images/FigDTUDatasetRes.png" width="100%" style="margin-left: auto;margin-right: auto;display: block;">
		  <p> Results of reconstruction for models in the DTU benchmark from 3 sparse views (as shown in the first column). The reconstruction results of prior methods are plagued by either geometric distortions (pixelNeRF and MVSNeRF ) or the loss of structural integrity (SparseNeuS and VolRecon ). Our SERES can reconstruct much more complete geometry with details. </p>

        </div>
        <br/>
        <h3 class="title is-4">Three views reconstruction on the BMVS benchmark</h3>
        <div class="content has-text-justified">
          <img src="./static/images/FigBlendedMVSRes.png" width="100%" style="margin-left: auto;margin-right: auto;display: block;">
		  <p>  Our SERES pipeline demonstrates superior performance in reconstructing models from the challenging BlendedMVS dataset using only 3 sparse views as shown in the first column. Unlike prior methods that often result in incomplete structures with holes, our approach can reconstruct more complete geometry with details </p>

        </div>
        <br/>
        <h3 class="title is-4">SERES in geometric reconstruction and view synthesis as a plugin</h3>
        <div class="content has-text-justified">
          <img src="./static/images/owl_update_size.png" width="100%" style="margin-left: auto;margin-right: auto;display: block;">
		  <img src="./static/images/FigQualitativeRes .png" width="100%" style="margin-left: auto;margin-right: auto;display: block;">
		  <p> Experimental tests of our SERES as plugins to improve both the Neus and the Neuralangelo baselines, where the owl model is reconstructed from 3 views. It can be observed that the quality of both the reconstructed geometry and the images obtained from novel view synthesis has been significantly improved to approach the ground truth </p>

        </div>
        <br/>
        <h3 class="title is-4">Ablation study</h3>
        <div class="content has-text-justified">
          <img src="./static/images/FigAblation.png" width="100%" style="margin-left: auto;margin-right: auto;display: block;">
		  <p> Ablation study to explain the functionality of each module of our SERES pipeline, where ‘W/o Semantic’ and ‘Fixed Semantic’ refer to the results without incorporating semantic priors vs giving a fixed semantic matching prior (i.e., without optimization). The results of ‘W/o Point-prompt’ vs ‘Full’ demonstrate that our point-prompt guided regularization effectively mitigates mesh noise and reduces shape ambiguity. The values of chamfer distance (CD) are also given for each results</p>

        </div>
        <br/>
        <h3 class="title is-4">Number of views on the reconstruction</h3>
        <div class="content has-text-justified">
          <img src="./static/images/Fig_NumOfViews.png" width="100%" style="margin-left: auto;margin-right: auto;display: block;">
          <p> This study demonstrates that using more number of views, ranging from 2 to 9, can reduce up to 40.8% of the chamfer distances on the results of reconstruction. As can be found from the zoom-views, more input views are helpful to address radiance-ambiguity therefore contribute to the reconstruction of nuanced disparities.          </p>
        </div>
       
      </div>
    </div>


  </div>
</section> -->

<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/files/under-review">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/SERES0" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template from <a
              href="https://github.com/nerfies/nerfies.github.io">here</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>
